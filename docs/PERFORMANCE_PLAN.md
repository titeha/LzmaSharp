# План по производительности: что оптимизируем и как

## 1) Сначала измеряем

Добавляем `BenchmarkDotNet` и минимум 3 бенчмарка:

- Decode LZMA2: 1 MiB / 64 MiB / 1 GiB (стриминг)
- Encode LZMA2: те же размеры
- «Плохие» и «хорошие» данные

Без бенчмарков оптимизация превращается в угадайку.

## 2) Главные источники затрат в LZMA/LZMA2

- Match finder (хеши, бинарные деревья/цепочки)
- Range coder (ветвления, доступ к probability arrays)
- Copy/дикшенари операции

## 3) Быстрые выигрыши в C#

- `ArrayPool<byte>` для больших буферов
- `Span<byte>`/`ReadOnlySpan<byte>`
- `unsafe` в hot loops (убрать bounds checks)
- `MethodImplOptions.AggressiveInlining` в микро‑функциях
- избегаем `MemoryStream.ToArray()` в горячем пути

## 4) SIMD

Реалистичные цели SIMD:

- ускорить сравнение матчей (memcmp/longest common prefix)
- ускорить копирование (если не хватает `Buffer.MemoryCopy`)

Range coder SIMD‑ится плохо (слишком ветвисто).

## 5) Многопоток

LZMA внутри блока последовательный, но можно:

- сжимать **независимые блоки** параллельно (reset dictionary)
- сжимать разные файлы параллельно (non-solid)

Solid‑режим — опционально.

## 6) GPU (GPGPU)

Честно: LZMA плохо ложится на GPU из‑за зависимости по данным.

Но GPU может быть полезен для:

- CRC32/хэши (если это реально bottleneck)
- фильтры (BCJ, delta)
- «батч» компрессия множества маленьких файлов (параллельно, но это спорно)

Поэтому GPU — после того, как CPU версия уже быстрая и измеренная.

